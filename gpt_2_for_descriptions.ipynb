{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt_2_for_descriptions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u6MjGQAuzWN",
        "colab_type": "text"
      },
      "source": [
        "# Sample Steam Store Descriptions with GPT-2\n",
        "Code inspired from https://github.com/woctezuma/sample-steam-descriptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KjP9yVVveN1",
        "colab_type": "text"
      },
      "source": [
        "## Setting the GPT-2 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A1zEYHxh304_"
      },
      "source": [
        "Install the Python package\n",
        "\n",
        "Reference: https://github.com/minimaxir/gpt-2-simple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ruwgwCuEHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gpt_2_simple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTkq7wEQwEkZ",
        "colab_type": "text"
      },
      "source": [
        "Download the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pdkhHU6wd12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ggC2Mc75BnB",
        "colab_type": "text"
      },
      "source": [
        "## Downloading GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r3939YUqT9K",
        "colab_type": "text"
      },
      "source": [
        "Choose between `117M` and `345M` models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW4vZzlyqOnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_name = '117M'\n",
        "model_name = '345M'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_hrBy2DqR5M",
        "colab_type": "text"
      },
      "source": [
        "Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-If30nT4ZCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkpviYXh4tHL",
        "colab_type": "text"
      },
      "source": [
        "## Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D4hzKfk4rIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gpt2.mount_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9sI2rah5OyB",
        "colab_type": "text"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d3NlwR97DRGt"
      },
      "source": [
        "#### Either get the data by yourself"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6h_g-wpDSSh",
        "colab_type": "text"
      },
      "source": [
        "Currently not possible because you:\n",
        "-   either need app details (slow to download),\n",
        "-   or aggregate.json (stored with Git LFS, not installed on Google Colab.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LPbkB998g-B",
        "colab_type": "text"
      },
      "source": [
        "#### Or get a data snapshot from me"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIR9fBid5U2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/woctezuma/sample-steam-descriptions/master/data/with_delimiters/concatenated_store_descriptions.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjmpOgoa5y7Q",
        "colab_type": "text"
      },
      "source": [
        "## Finetune GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WDz30tL5-yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = 'concatenated_store_descriptions.txt'\n",
        "\n",
        "run_name = model_name + '_descriptions'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfg4HYZl56JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              run_name=run_name,\n",
        "              dataset=file_name,\n",
        "              model_name=model_name,\n",
        "              steps=1000,\n",
        "              restore_from='fresh',   # change to 'latest' to resume training\n",
        "              print_every=10,   # how many steps between printing progress\n",
        "              sample_every=200,   # how many steps to print a demo sample\n",
        "              save_every=500   # how many steps between saving checkpoint              \n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlHGcNdYucbT",
        "colab_type": "text"
      },
      "source": [
        "## Save a Trained Model Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAyu3yNP6Uls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# mount_folder = '/content/gdrive'\n",
        "# drive.mount(mount_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsOYYVXfuhN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !mkdir -p '/content/gdrive/My Drive/checkpoint/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpbP2iERGfu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gpt2.copy_checkpoint_to_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEwkRvCn6XZW",
        "colab_type": "text"
      },
      "source": [
        "## Load a Trained Model Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNvn7Vrmuj7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p checkpoint/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dELSgpoC6Z-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gpt2.copy_checkpoint_from_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqDaWVAo6cn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sess = gpt2.start_tf_sess()\n",
        "\n",
        "# gpt2.load_gpt2(sess,\n",
        "#                run_name=run_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX8KFoKR6g-o",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzAzQvF8v8KH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temperature=0.7 # Default is 0.7, but you may want to increase the temperature, especially if your dataset is small, to avoid copying text.\n",
        "\n",
        "num_samples = 3\n",
        "num_batches = 3 # Unique to GPT-2, you can pass a batch_size to generate multiple samples in parallel, giving a massive speedup."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYC30GEi6kPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              nsamples=num_samples,             \n",
        "              batch_size=num_batches,\n",
        "              temperature=temperature)              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrZBWas662k_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              nsamples=num_samples,\n",
        "              batch_size=num_batches,\n",
        "              temperature=temperature,              \n",
        "              prefix='<|startoftext|>Half-Life 3 is the long-awaited sequel in the Half-Life franchise developped by Valve',\n",
        "              truncate='<|endoftext|>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjHTB5Mg9rno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              nsamples=num_samples,\n",
        "              batch_size=num_batches,\n",
        "              temperature=temperature,              \n",
        "              prefix='<|startoftext|>Spelunky 2 is the sequel of the most acclaimed rogue-like platformer of all-time',\n",
        "              truncate='<|endoftext|>')              "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}